import tkinter as tk
import random
import threading
import os
import json
from PIL import Image, ImageTk
import numpy as np
import queue
import time

class ChatGUI:
    def __init__(self, root, log_path, mic_enabled=False, asr_loaded=False, llm_loaded=False, ai_name="L"):
        self.root = root
        self.root.title("AIé™ªä¼´ç³»ç»Ÿ")
        self.log_path = log_path
        self._ai_name = ai_name
        
        self.root.resizable(False, False)
        
        self.window_width = 800
        self.window_height = 500
        self.root.geometry(f"{self.window_width}x{self.window_height}")
        
        self.bg_image_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "photo1.jpg")
        
        self._mic_enabled = mic_enabled
        self._asr_loaded = asr_loaded
        self._llm_loaded = llm_loaded
        
        self._model_manager = None
        self._is_recording = False
        self._recording_thread = None
        self._audio_queue = queue.Queue()
        
        self._tts_playing = False
        self._interrupted = False
        self._current_speech_text = ""
        
        self._emotion_analyzer = None
        self._voice_adjuster = None
        self._interrupt_detector = None
        self._vad = None
        
        self._current_user_emotion = "calm"
        self._current_speech_rate = 1.0
        
        self._init_modules()
        
        self.load_background_image()
        
        if not os.path.exists(log_path):
            try:
                os.makedirs(log_path)
            except Exception as e:
                print(f"åˆ›å»ºæ—¥å¿—ç›®å½•å¤±è´¥: {e}")
        
        self.update_log_path(log_path)
        
        self._init_model_manager()
        
        self.chat_history = []
        
        try:
            from app.core.tts import TextToSpeech
            self.tts = TextToSpeech()
            self.setup_voice_parameters()
        except Exception as e:
            self.tts = None
        
        self.setup_main_background()
        
        self.create_chat_history_area()
        
        self.create_right_image_area()
        
        self.create_input_area()
        
        self.create_control_area()
        
        self.create_bottom_right_image_area()
        
        self.create_emotion_indicator()
        

        
        self.load_chat_history()
        
        if not self.chat_history:
            welcome_message = f"ä½ å¥½ï¼Œæˆ‘æ˜¯{self._ai_name}"
            self.display_message(self._ai_name, welcome_message)
            
            self.root.update_idletasks()
            
            thread = threading.Thread(target=self._speak_with_interrupt, args=(welcome_message,))
            thread.daemon = True
            thread.start()
    
    def _init_modules(self):
        try:
            from app.core.emotion import EmotionAnalyzer
            self._emotion_analyzer = EmotionAnalyzer()
            print("[Info] æƒ…æ„Ÿåˆ†ææ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"[Error] æƒ…æ„Ÿåˆ†ææ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            from app.core.voice_adjuster import VoiceAdjuster
            self._voice_adjuster = VoiceAdjuster()
            print("[Info] å£°éŸ³è°ƒèŠ‚æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"[Error] å£°éŸ³è°ƒèŠ‚æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            from app.core.interrupt import InterruptDetector
            self._interrupt_detector = InterruptDetector()
            print("[Info] æ‰“æ–­æ£€æµ‹æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"[Error] æ‰“æ–­æ£€æµ‹æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            from app.core.vad import VoiceActivityDetector
            self._vad = VoiceActivityDetector()
            print("[Info] VADæ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"[Error] VADæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _init_model_manager(self):
        try:
            from app.models.model_manager import model_manager
            self._model_manager = model_manager
            self._model_manager.set_log_path(self.log_path)
        except Exception as e:
            print(f"[Error] åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨å¤±è´¥: {e}")
    
    def load_background_image(self):
        try:
            self.original_bg_image = Image.open(self.bg_image_path)
            self.original_bg_image = self.original_bg_image.resize(
                (self.window_width, self.window_height), Image.Resampling.LANCZOS
            )
        except Exception as e:
            self.original_bg_image = None
    
    def setup_main_background(self):
        self.root.configure(bg='#ffffff')
    
    def create_chat_history_area(self):
        self.chat_area_x = 10
        self.chat_area_y = 10
        self.chat_area_width = 585
        self.chat_area_height = 340
        
        self.chat_frame = tk.Frame(self.root, width=self.chat_area_width, height=self.chat_area_height, bg='#ffffff')
        self.chat_frame.place(x=self.chat_area_x, y=self.chat_area_y)
        self.chat_frame.pack_propagate(False)
        
        self.chat_history_text = tk.Text(
            self.chat_frame, width=70, height=20, 
            font=("SimHei", 12, "bold"), 
            bg='#ffffff', relief='flat', bd=0,
            highlightthickness=0,
            insertbackground='#000000',
            fg='#1a1a1a', padx=10, pady=10,
            wrap=tk.WORD
        )
        self.chat_history_text.place(x=0, y=0, relwidth=0.95, relheight=1)
        
        self.chat_scrollbar = tk.Scrollbar(self.chat_frame, command=self.chat_history_text.yview)
        self.chat_scrollbar.place(relx=0.95, y=0, relwidth=0.05, relheight=1)
        self.chat_history_text.config(yscrollcommand=self.chat_scrollbar.set)
        
        self.chat_history_text.config(state=tk.DISABLED)
    
    def create_right_image_area(self):
        self.image_area_x = 605
        self.image_area_y = 10
        self.image_area_width = 185
        self.image_area_height = 340
        
        self.image_frame = tk.Frame(self.root, width=self.image_area_width, height=self.image_area_height, bg='#ffffff')
        self.image_frame.place(x=self.image_area_x, y=self.image_area_y)
        self.image_frame.pack_propagate(False)
        
        try:
            photo2_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "photo2.jpg")
            original_image = Image.open(photo2_path)
            
            width, height = original_image.size
            left_crop = original_image.crop((0, 0, width // 2, height))
            
            crop_width, crop_height = left_crop.size
            target_width = self.image_area_width
            target_height = int(crop_height * (target_width / crop_width))
            
            left_crop = left_crop.resize(
                (target_width, target_height), 
                Image.Resampling.LANCZOS
            )
            
            self.right_image = ImageTk.PhotoImage(left_crop)
            
            self.image_label = tk.Label(self.image_frame, image=self.right_image, bg='#ffffff')
            self.image_label.place(x=0, y=0, relwidth=1, relheight=(target_height / self.image_area_height))
        except Exception:
            self.image_label = tk.Label(
                self.image_frame, 
                text="å›¾ç‰‡åŒºåŸŸ", 
                bg='#ffffff', 
                font=("SimHei", 12)
            )
            self.image_label.place(x=0, y=0, relwidth=1, relheight=1)
    
    def create_input_area(self):
        self.input_area_x = 10
        self.input_area_y = 400
        self.input_area_width = 585
        self.input_area_height = 60
        
        self.input_frame = tk.Frame(self.root, width=self.input_area_width, height=self.input_area_height, bg='#ffffff')
        self.input_frame.place(x=self.input_area_x, y=self.input_area_y)
        self.input_frame.pack_propagate(False)
        
        self.mic_button = tk.Button(
            self.input_frame, text="ğŸ¤", command=self.toggle_recording,
            font=("SimHei", 18), width=5, bg='#5cb85c', 
            relief='flat', bd=0, highlightthickness=0,
            activebackground='#449d44', fg='#ffffff', cursor='hand2'
        )
        self.mic_button.place(relx=0.5, rely=0.5, anchor='center', relwidth=0.2, relheight=0.8)
    
    def create_control_area(self):
        pass
    
    def create_bottom_right_image_area(self):
        self.bottom_image_area_x = 605
        self.bottom_image_area_y = 350
        self.bottom_image_area_width = 185
        self.bottom_image_area_height = 120
        
        self.bottom_image_frame = tk.Frame(self.root, width=self.bottom_image_area_width, height=self.bottom_image_area_height, bg='#ffffff')
        self.bottom_image_frame.place(x=self.bottom_image_area_x, y=self.bottom_image_area_y)
        self.bottom_image_frame.pack_propagate(False)
        
        try:
            photo3_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "photo3.png")
            original_image = Image.open(photo3_path)
            
            width, height = original_image.size
            
            crop_size = min(width, height) // 2
            top_left_crop = original_image.crop((0, 0, crop_size, crop_size))
            
            top_left_crop = top_left_crop.resize(
                (self.bottom_image_area_width, self.bottom_image_area_height), 
                Image.Resampling.LANCZOS
            )
            
            self.bottom_image = ImageTk.PhotoImage(top_left_crop)
            
            self.bottom_image_label = tk.Label(self.bottom_image_frame, image=self.bottom_image, bg='#ffffff')
            self.bottom_image_label.place(relx=0.5, rely=0.5, anchor='center')
        except Exception:
            self.bottom_image_label = tk.Label(
                self.bottom_image_frame, 
                text="", 
                bg='#ffffff'
            )
            self.bottom_image_label.place(x=0, y=0, relwidth=1, relheight=1)
    
    def create_emotion_indicator(self):
        self.emotion_frame = tk.Frame(self.root, width=185, height=30, bg='#ffffff')
        self.emotion_frame.place(x=605, y=470)
        
        self.emotion_label = tk.Label(
            self.emotion_frame,
            text="æƒ…æ„Ÿ: å¹³é™",
            font=("SimHei", 10),
            bg='#ffffff',
            fg='#666666'
        )
        self.emotion_label.place(relx=0.5, rely=0.5, anchor='center')
    
    def setup_voice_parameters(self):
        if self.tts:
            speed = 1.2
            volume = 1.0
            voice_id = 0
            try:
                voices = []
                if hasattr(self.tts, 'voices') and self.tts.voices:
                    voices = self.tts.voices
                elif hasattr(self.tts, 'engine') and self.tts.engine:
                    voices = self.tts.engine.getProperty('voices')
                
                for i, voice in enumerate(voices):
                    if 'å¥³' in voice.name or 'female' in voice.name.lower() or 'huihui' in voice.name.lower():
                        voice_id = i
                        break
            except Exception:
                pass
            
            try:
                self.tts.set_parameters(speed=speed, volume=volume, voice_id=voice_id)
            except Exception:
                pass
    
    def _adjust_voice_by_emotion(self, emotion):
        if self._voice_adjuster and self.tts:
            params = self._voice_adjuster.adjust_voice_by_emotion(emotion)
            self.tts.set_parameters(
                speed=params.get("speed", 1.0),
                pitch=params.get("pitch", 1.0),
                volume=params.get("volume", 1.0)
            )
            print(f"[Info] æ ¹æ®æƒ…æ„Ÿè°ƒæ•´å£°éŸ³å‚æ•°: {params}")
    
    def _adjust_voice_by_speech_rate(self, speech_rate):
        if self._voice_adjuster and self.tts:
            params = self._voice_adjuster.adjust_voice_by_speech_rate(speech_rate)
            self.tts.set_parameters(
                speed=params.get("speed", 1.0),
                pitch=params.get("pitch", 1.0),
                volume=params.get("volume", 1.0)
            )
            print(f"[Info] æ ¹æ®è¯­é€Ÿè°ƒæ•´å£°éŸ³å‚æ•°: {params}")
    
    def _adjust_voice_combined(self, emotion, speech_rate):
        if self._voice_adjuster and self.tts:
            params = self._voice_adjuster.adjust_voice_combined(emotion, speech_rate)
            self.tts.set_parameters(
                speed=params.get("speed", 1.0),
                pitch=params.get("pitch", 1.0),
                volume=params.get("volume", 1.0)
            )
            print(f"[Info] ç»¼åˆè°ƒæ•´å£°éŸ³å‚æ•°: {params}")
    
    def _analyze_emotion(self, audio_data, sample_rate=16000):
        if self._emotion_analyzer:
            try:
                emotion, features = self._emotion_analyzer.analyze_audio(audio_data, sample_rate)
                return emotion, features
            except Exception as e:
                print(f"[Error] æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
        return "calm", {}
    
    def _update_emotion_indicator(self, emotion):
        emotion_names = {
            "happy": "å¼€å¿ƒ",
            "sad": "éš¾è¿‡",
            "angry": "æ„¤æ€’",
            "anxious": "ç„¦è™‘",
            "calm": "å¹³é™",
            "surprised": "æƒŠè®¶"
        }
        emotion_text = emotion_names.get(emotion, emotion)
        self.root.after(0, lambda: self.emotion_label.config(text=f"æƒ…æ„Ÿ: {emotion_text}"))
    
    def _speak_with_interrupt(self, message):
        if not self.tts:
            return False
        
        self._tts_playing = True
        self._current_speech_text = message
        self._interrupted = False
        
        if self._interrupt_detector:
            self._interrupt_detector.set_tts_playing(True)
        
        # å¯åŠ¨æ‰“æ–­æ£€æµ‹çº¿ç¨‹
        interrupt_thread = threading.Thread(target=self._monitor_interrupt)
        interrupt_thread.daemon = True
        interrupt_thread.start()
        
        try:
            result = self.tts.speak(message)
        except Exception:
            result = False
        
        self._tts_playing = False
        if self._interrupt_detector:
            self._interrupt_detector.set_tts_playing(False)
        
        return result
    
    def _monitor_interrupt(self):
        """ç›‘æ§ç”¨æˆ·è¯­éŸ³è¾“å…¥ï¼Œæ£€æµ‹æ‰“æ–­"""
        try:
            import pyaudio
            
            CHUNK = 1024
            FORMAT = pyaudio.paInt16
            CHANNELS = 1
            RATE = 16000
            
            p = pyaudio.PyAudio()
            stream = p.open(format=FORMAT,
                           channels=CHANNELS,
                           rate=RATE,
                           input=True,
                           frames_per_buffer=CHUNK)
            
            while self._tts_playing and not self._interrupted:
                data = stream.read(CHUNK, exception_on_overflow=False)
                
                # ä½¿ç”¨VADæ£€æµ‹è¯­éŸ³æ´»åŠ¨
                if self._vad:
                    is_voice = self._vad.is_voice(data)
                    if is_voice:
                        # æ£€æµ‹åˆ°ç”¨æˆ·è¯­éŸ³ï¼Œæ‰“æ–­TTSæ’­æ”¾
                        print("[Info] æ£€æµ‹åˆ°ç”¨æˆ·è¯­éŸ³ï¼Œæ‰“æ–­TTSæ’­æ”¾")
                        if self.tts:
                            self.tts.stop()
                        self._interrupted = True
                        self._tts_playing = False
                        if self._interrupt_detector:
                            self._interrupt_detector.set_tts_playing(False)
                        break
                
                # ä½¿ç”¨æ‰“æ–­æ£€æµ‹å™¨
                if self._interrupt_detector:
                    audio_chunk = np.frombuffer(data, dtype=np.int16)
                    energy = np.abs(audio_chunk).mean()
                    if energy > 500 and self._interrupt_detector.get_interrupt_status():
                        print("[Info] æ‰“æ–­æ£€æµ‹å™¨è§¦å‘ï¼Œæ‰“æ–­TTSæ’­æ”¾")
                        if self.tts:
                            self.tts.stop()
                        self._interrupted = True
                        self._tts_playing = False
                        self._interrupt_detector.set_tts_playing(False)
                        break
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            
        except Exception as e:
            print(f"[Error] æ‰“æ–­ç›‘æ§å¤±è´¥: {e}")
    
    def speak_message(self, message):
        return self._speak_with_interrupt(message)
    
    def test_tts(self):
        """æµ‹è¯•TTSåŠŸèƒ½"""
        test_message = "è¯­éŸ³æµ‹è¯•ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯"
        print(f"[Info] æµ‹è¯•TTS: {test_message}")
        if self.tts:
            try:
                result = self.tts.speak(test_message)
                print(f"[Info] TTSæµ‹è¯•ç»“æœ: {result}")
            except Exception as e:
                print(f"[Error] TTSæµ‹è¯•å¤±è´¥: {e}")
        else:
            print("[Error] TTSæœªåˆå§‹åŒ–")
    
    def display_message(self, sender, message):
        self.chat_history_text.config(state=tk.NORMAL)
        self.chat_history_text.insert(tk.END, f"{sender}: {message}\n\n")
        self.chat_history_text.config(state=tk.DISABLED)
        self.chat_history_text.see(tk.END)
        
        self.chat_history.append({"sender": sender, "message": message})
        
        self.save_chat_history()
    
    def toggle_recording(self):
        if self._is_recording:
            self._is_recording = False
            self.mic_button.config(text="ğŸ¤", bg='#5cb85c')
        else:
            self._is_recording = True
            self.mic_button.config(text="â¹", bg='#d9534f')
            
            if self._tts_playing and self.tts:
                self.tts.stop()
                self._interrupted = True
                self._tts_playing = False
                if self._interrupt_detector:
                    self._interrupt_detector.set_tts_playing(False)
            
            self._recording_thread = threading.Thread(target=self._record_audio_vad)
            self._recording_thread.daemon = True
            self._recording_thread.start()
    
    def _record_audio_vad(self):
        try:
            import pyaudio
            
            CHUNK = 1024
            FORMAT = pyaudio.paInt16
            CHANNELS = 1
            RATE = 16000
            
            SILENCE_THRESHOLD = 500
            SILENCE_FRAMES = 25
            
            p = pyaudio.PyAudio()
            
            stream = p.open(format=FORMAT,
                           channels=CHANNELS,
                           rate=RATE,
                           input=True,
                           frames_per_buffer=CHUNK)
            
            frames = []
            silence_count = 0
            has_speech = False
            start_time = time.time()
            
            self.root.after(0, lambda: self.mic_button.config(text="â¹", bg='#d9534f'))
            
            while self._is_recording:
                data = stream.read(CHUNK, exception_on_overflow=False)
                frames.append(data)
                
                audio_chunk = np.frombuffer(data, dtype=np.int16)
                energy = np.abs(audio_chunk).mean()
                
                # ä½¿ç”¨VADæ£€æµ‹è¯­éŸ³æ´»åŠ¨
                vad_detected = False
                if self._vad:
                    is_voice = self._vad.is_voice(data)
                    if is_voice:
                        has_speech = True
                        silence_count = 0
                        vad_detected = True
                    elif has_speech:
                        silence_count += 1
                
                # å¦‚æœVADä¸å¯ç”¨æˆ–æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œä½¿ç”¨èƒ½é‡æ£€æµ‹ä½œä¸ºåå¤‡
                if not vad_detected:
                    if energy > SILENCE_THRESHOLD:
                        has_speech = True
                        silence_count = 0
                    elif has_speech:
                        silence_count += 1
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢å½•éŸ³
                if has_speech and silence_count > SILENCE_FRAMES:
                    break
                
                # è¶…æ—¶ä¿æŠ¤ï¼Œæœ€å¤šå½•éŸ³30ç§’
                if time.time() - start_time > 30:
                    break
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            
            if frames and has_speech:
                audio_data = np.frombuffer(b''.join(frames), dtype=np.int16)
                audio_data_float = audio_data.astype(np.float32) / 32768.0
                
                speech_duration = len(audio_data) / RATE
                
                self.root.after(0, lambda: self.mic_button.config(text="è¯†åˆ«ä¸­...", bg='#f0ad4e'))
                
                emotion, features = self._analyze_emotion(audio_data_float, RATE)
                self._current_user_emotion = emotion
                self._update_emotion_indicator(emotion)
                
                text = self._transcribe_audio(audio_data_float)
                
                if text and speech_duration > 0:
                    text_length = len(text)
                    self._current_speech_rate = text_length / speech_duration
                    # è‡ªåŠ¨å‘é€è¯†åˆ«ç»“æœ
                    self.send_message(text)
                
            self.root.after(0, lambda: self.mic_button.config(text="ğŸ¤", bg='#5cb85c'))
            
        except Exception as e:
            print(f"[Error] å½•éŸ³å¤±è´¥: {e}")
            self.root.after(0, lambda: self.mic_button.config(text="ğŸ¤", bg='#5cb85c'))
    
    def _transcribe_audio(self, audio_data):
        if self._model_manager:
            asr_model = self._model_manager.get_asr_model()
            if asr_model:
                try:
                    return asr_model.transcribe(audio_data)
                except Exception as e:
                    print(f"[Error] ASRè¯†åˆ«å¤±è´¥: {e}")
        
        try:
            from app.core.asr import SpeechRecognizer
            recognizer = SpeechRecognizer()
            return recognizer.recognize_from_microphone()
        except Exception as e:
            print(f"[Error] å¤‡ç”¨ASRè¯†åˆ«å¤±è´¥: {e}")
        
        return ""
    
    def send_message(self, user_input):
        if not user_input:
            return
        
        if self.tts:
            try:
                self.tts.stop()
            except Exception:
                pass
        
        self.display_message("è¿œè¾¹", user_input)
        
        self._adjust_voice_combined(self._current_user_emotion, self._current_speech_rate)
        
        response = self._get_llm_response(user_input, self._current_user_emotion)
        
        enhanced_response = f"{response}"
        
        self.display_message(self._ai_name, enhanced_response)
        
        self.root.update_idletasks()
        
        thread = threading.Thread(target=self._speak_with_interrupt, args=(enhanced_response,))
        thread.daemon = True
        thread.start()
    
    def _get_llm_response(self, user_input, emotion=None):
        if self._model_manager:
            llm_model = self._model_manager.get_llm_model()
            if llm_model:
                try:
                    return llm_model.get_response(user_input, emotion)
                except Exception as e:
                    print(f"[Error] LLMå›å¤å¤±è´¥: {e}")
        
        try:
            from app.core.chat import LocalChatModel
            chat_model = LocalChatModel()
            return chat_model.get_response(user_input)
        except Exception as e:
            print(f"[Error] æœ¬åœ°æ¨¡å‹å›å¤å¤±è´¥: {e}")
        
        return self.get_simple_response(user_input)
    
    def get_simple_response(self, user_input):
        keywords = {
            "greeting": ["ä½ å¥½", "å—¨", "å“ˆå–½", "æ—©ä¸Šå¥½", "ä¸‹åˆå¥½", "æ™šä¸Šå¥½"],
            "farewell": ["å†è§", "æ‹œæ‹œ", "ä¸‹æ¬¡è§", "æ™šå®‰"],
            "thanks": ["è°¢è°¢", "å¤šè°¢", "æ„Ÿè°¢", "éº»çƒ¦äº†"],
            "weather": ["å¤©æ°”", "æ™´å¤©", "ä¸‹é›¨", "ä¸‹é›ª", "æ¸©åº¦"],
            "hobby": ["çˆ±å¥½", "å–œæ¬¢", "å…´è¶£", "å¨±ä¹"]
        }
        
        templates = {
            "greeting": ["ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿ", "å—¨ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ", "ä½ å¥½ï¼Œæœ€è¿‘æ€ä¹ˆæ ·å‘€ï¼Ÿ"],
            "farewell": ["å†è§ï¼ç¥ä½ æœ‰æ„‰å¿«çš„ä¸€å¤©ï¼", "æ‹œæ‹œï¼ŒæœŸå¾…ä¸‹æ¬¡å’Œä½ èŠå¤©ï¼", "å†è§ï¼Œæœ‰éœ€è¦éšæ—¶å‘Šè¯‰æˆ‘ï¼"],
            "thanks": ["ä¸å®¢æ°”ï¼Œèƒ½å¸®åˆ°ä½ æˆ‘å¾ˆå¼€å¿ƒï¼", "æ²¡å…³ç³»ï¼Œè¿™æ˜¯æˆ‘åº”è¯¥åšçš„ã€‚", "ä¸ç”¨è°¢ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ï¼"],
            "weather": ["ä»Šå¤©å¤©æ°”çœ‹èµ·æ¥ä¸é”™å‘¢ï¼", "æœ€è¿‘å¤©æ°”å˜åŒ–æŒºå¤§çš„ï¼Œæ³¨æ„å¢å‡è¡£ç‰©å“¦ã€‚", "å¤©æ°”çœŸçš„å¾ˆé‡è¦ï¼Œå½±å“æˆ‘ä»¬çš„å¿ƒæƒ…å‘¢ã€‚"],
            "hobby": ["ä½ çš„çˆ±å¥½å¬èµ·æ¥å¾ˆæœ‰è¶£ï¼", "æˆ‘ä¹Ÿå¾ˆå–œæ¬¢ç±»ä¼¼çš„æ´»åŠ¨å‘¢ã€‚", "çˆ±å¥½å¯ä»¥ä¸°å¯Œæˆ‘ä»¬çš„ç”Ÿæ´»ï¼ŒçœŸä¸é”™ï¼"],
            "default": ["æˆ‘ç†è§£ä½ çš„æ„æ€ã€‚", "è¿™æ˜¯ä¸ªæœ‰è¶£çš„è¯é¢˜ã€‚", "æˆ‘ä¸å¤ªç¡®å®šï¼Œæˆ‘ä»¬å¯ä»¥æ¢ä¸ªè¯é¢˜èŠèŠã€‚", "èƒ½å†è¯¦ç»†è¯´è¯´å—ï¼Ÿ"]
        }
        
        intent = "default"
        for key, word_list in keywords.items():
            for word in word_list:
                if word in user_input:
                    intent = key
                    break
            if intent != "default":
                break
        
        return random.choice(templates[intent])
    
    def update_log_path(self, log_path):
        try:
            import app.utils.logger
            
            if hasattr(app.utils.logger, 'set_log_directory'):
                app.utils.logger.set_log_directory(log_path)
            elif hasattr(app.utils.logger, 'setup_logger'):
                app.utils.logger.app_logger = app.utils.logger.setup_logger('app', os.path.join(log_path, 'app.log'))
                app.utils.logger.audio_logger = app.utils.logger.setup_logger('audio', os.path.join(log_path, 'audio.log'))
                app.utils.logger.chat_logger = app.utils.logger.setup_logger('chat', os.path.join(log_path, 'chat.log'))
                app.utils.logger.emotion_logger = app.utils.logger.setup_logger('emotion', os.path.join(log_path, 'emotion.log'))
        except Exception:
            pass
    
    def load_chat_history(self):
        try:
            chat_history_file = os.path.join(self.log_path, "chat_history.json")
            
            if os.path.exists(chat_history_file):
                with open(chat_history_file, 'r', encoding='utf-8') as f:
                    self.chat_history = json.load(f)
                
                print(f"[Info] åŠ è½½èŠå¤©å†å²è®°å½•æˆåŠŸï¼Œå…±{len(self.chat_history)}æ¡è®°å½•")
                
                for record in self.chat_history:
                    sender = record.get('sender', '')
                    message = record.get('message', '')
                    if sender and message:
                        self.chat_history_text.config(state=tk.NORMAL)
                        self.chat_history_text.insert(tk.END, f"{sender}: {message}\n\n")
                        self.chat_history_text.config(state=tk.DISABLED)
                
                self.chat_history_text.see(tk.END)
            else:
                print(f"[Info] èŠå¤©å†å²æ–‡ä»¶ä¸å­˜åœ¨: {chat_history_file}")
        except Exception as e:
            print(f"[Error] åŠ è½½èŠå¤©å†å²è®°å½•å¤±è´¥: {e}")
    
    def save_chat_history(self):
        try:
            chat_history_file = os.path.join(self.log_path, "chat_history.json")
            
            with open(chat_history_file, 'w', encoding='utf-8') as f:
                json.dump(self.chat_history, f, ensure_ascii=False, indent=2)
            
            print(f"[Info] ä¿å­˜èŠå¤©å†å²è®°å½•æˆåŠŸï¼Œå…±{len(self.chat_history)}æ¡è®°å½•")
        except Exception as e:
            print(f"[Error] ä¿å­˜èŠå¤©å†å²è®°å½•å¤±è´¥: {e}")
    
    def refresh_app(self):
        if self.tts:
            try:
                self.tts.stop()
            except Exception:
                pass
        
        self.chat_history.clear()
        
        self.chat_history_text.config(state=tk.NORMAL)
        self.chat_history_text.delete(1.0, tk.END)
        
        try:
            chat_history_file = os.path.join(self.log_path, "chat_history.json")
            if os.path.exists(chat_history_file):
                os.remove(chat_history_file)
                print(f"[Info] å·²åˆ é™¤èŠå¤©å†å²æ–‡ä»¶: {chat_history_file}")
        except Exception as e:
            print(f"[Error] åˆ é™¤èŠå¤©å†å²æ–‡ä»¶å¤±è´¥: {e}")
        
        self._current_user_emotion = "calm"
        self._update_emotion_indicator("calm")
        
        welcome_message = f"ä½ å¥½ï¼Œæˆ‘æ˜¯{self._ai_name}"
        self.display_message(self._ai_name, welcome_message)
        
        thread = threading.Thread(target=self._speak_with_interrupt, args=(welcome_message,))
        thread.daemon = True
        thread.start()
